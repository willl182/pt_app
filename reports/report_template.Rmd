---
title: "Informe Final del Ensayo de Aptitud (EA)"
subtitle: "Medición de Gases Contaminantes Criterio SO₂, CO, O₃, NO, NO₂"
author: "Laboratorio CALAIRE"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: true
    toc_depth: 3
params:
  hom_data: NA
  stab_data: NA
  summary_data: NA
  metric: "z"
  method: "1"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
library(tidyverse)
library(knitr)
library(kableExtra)
library(patchwork)
library(outliers)

# Helper Functions
calculate_niqr <- function(x) {
  x_clean <- x[is.finite(x)]
  if (length(x_clean) < 2) {
    return(NA_real_)
  }
  quartiles <- stats::quantile(x_clean, probs = c(0.25, 0.75), na.rm = TRUE, type = 7)
  0.7413 * (quartiles[2] - quartiles[1])
}

get_wide_data <- function(df, target_pollutant) {
  filtered <- df %>% filter(pollutant == target_pollutant)
  if (nrow(filtered) == 0) {
    return(NULL)
  }
  filtered %>%
    select(-pollutant) %>%
    pivot_wider(names_from = replicate, values_from = value, names_prefix = "sample_")
}

compute_homogeneity_metrics <- function(hom_data_full, target_pollutant, target_level) {
  wide_df <- get_wide_data(hom_data_full, target_pollutant)
  if (is.null(wide_df)) return(NULL)
  
  level_data <- wide_df %>%
    filter(level == target_level) %>%
    select(starts_with("sample_"))
  
  if (nrow(level_data) < 2 || ncol(level_data) < 2) return(NULL)
  
  g <- nrow(level_data)
  m <- ncol(level_data)
  
  hom_data <- level_data %>%
    mutate(Item = factor(row_number())) %>%
    pivot_longer(cols = -Item, names_to = "replicate", values_to = "Result")
  
  first_sample_results <- level_data %>% pull(sample_1)
  median_val <- median(first_sample_results, na.rm = TRUE)
  mad_e <- 1.483 * median(abs(first_sample_results - median_val), na.rm = TRUE)
  
  hom_item_stats <- hom_data %>%
    group_by(Item) %>%
    summarise(
      mean = mean(Result, na.rm = TRUE),
      diff = max(Result, na.rm = TRUE) - min(Result, na.rm = TRUE),
      .groups = "drop"
    )
  
  hom_x_t_bar <- mean(hom_item_stats$mean, na.rm = TRUE)
  hom_s_x_bar_sq <- var(hom_item_stats$mean, na.rm = TRUE)
  hom_s_xt <- sqrt(hom_s_x_bar_sq)
  hom_wt <- abs(hom_item_stats$diff)
  hom_sw <- sqrt(sum(hom_wt^2) / (2 * length(hom_wt)))
  hom_ss <- sqrt(abs(hom_s_xt^2 - ((hom_sw^2) / 2)))
  
  hom_sigma_pt <- mad_e
  hom_c_criterion <- 0.3 * hom_sigma_pt
  
  list(
    ss = hom_ss,
    c_criterion = hom_c_criterion,
    sigma_pt = hom_sigma_pt,
    general_mean = hom_x_t_bar,
    passed = hom_ss <= hom_c_criterion
  )
}

compute_stability_metrics <- function(stab_data_full, target_pollutant, target_level, hom_results) {
  wide_df <- get_wide_data(stab_data_full, target_pollutant)
  if (is.null(wide_df)) return(NULL)
  
  level_data <- wide_df %>%
    filter(level == target_level) %>%
    select(starts_with("sample_"))
  
  if (nrow(level_data) < 2 || ncol(level_data) < 2) return(NULL)
  
  stab_data <- level_data %>%
    mutate(Item = factor(row_number())) %>%
    pivot_longer(cols = -Item, names_to = "replicate", values_to = "Result")
    
  stab_item_stats <- stab_data %>%
    group_by(Item) %>%
    summarise(mean = mean(Result, na.rm = TRUE), .groups = "drop")
    
  stab_x_t_bar <- mean(stab_item_stats$mean, na.rm = TRUE)
  diff_hom_stab <- abs(stab_x_t_bar - hom_results$general_mean)
  
  stab_c_criterion <- 0.3 * hom_results$sigma_pt
  
  list(
    check_value = diff_hom_stab,
    c_criterion = stab_c_criterion,
    passed = diff_hom_stab <= stab_c_criterion
  )
}

run_algorithm_a <- function(values, max_iter = 50) {
  values <- values[is.finite(values)]
  if (length(values) < 3) return(list(mean = NA, sd = NA))
  
  x_star <- median(values, na.rm = TRUE)
  s_star <- 1.483 * median(abs(values - x_star), na.rm = TRUE)
  
  for (i in 1:max_iter) {
    u_val <- (values - x_star) / (1.5 * s_star)
    w <- ifelse(abs(u_val) <= 1, 1, 1/u_val^2)
    x_new <- sum(w * values) / sum(w)
    s_new <- sqrt(sum(w * (values - x_new)^2) / sum(w))
    
    if (abs(x_new - x_star) < 1e-4 & abs(s_new - s_star) < 1e-4) break
    x_star <- x_new
    s_star <- s_new
  }
  return(list(mean = x_star, sd = s_star))
}

calculate_scores <- function(df, pollutant_name, method_code) {
  df_sub <- df %>% filter(pollutant == pollutant_name)
  
  # Determine targets based on method
  targets <- NULL
  
  if (method_code == "1") { # Reference
    ref_data <- df_sub %>% filter(participant_id == "ref")
    if(nrow(ref_data) > 0) {
      targets <- ref_data %>% 
        group_by(level) %>% 
        summarise(
          x_pt = mean(mean_value), 
          u_xpt = mean(sd_value), 
          sigma_pt = x_pt * 0.1, 
          .groups = "drop"
        )
    }
  } else if (method_code == "3") { # Algorithm A
     targets <- df_sub %>%
      group_by(level) %>%
      summarise(
        algo_res = list(run_algorithm_a(mean_value)),
        x_pt = algo_res[[1]]$mean,
        s_star = algo_res[[1]]$sd,
        u_xpt = 1.25 * s_star / sqrt(n()),
        sigma_pt = s_star,
        .groups = "drop"
      ) %>%
      select(-algo_res, -s_star)
  } else if (method_code == "2a") { # Consensus MADe
     targets <- df_sub %>%
      group_by(level) %>%
      summarise(
        x_pt = median(mean_value, na.rm = TRUE),
        mad_val = median(abs(mean_value - median(mean_value, na.rm = TRUE)), na.rm = TRUE),
        sigma_pt = 1.483 * mad_val,
        u_xpt = 1.25 * sigma_pt / sqrt(n()),
        .groups = "drop"
      ) %>%
      select(-mad_val)
  } else if (method_code == "2b") { # Consensus nIQR
     targets <- df_sub %>%
      group_by(level) %>%
      summarise(
        x_pt = median(mean_value, na.rm = TRUE),
        sigma_pt = calculate_niqr(mean_value),
        u_xpt = 1.25 * sigma_pt / sqrt(n()),
        .groups = "drop"
      )
  }

  if (is.null(targets)) {
      # Fallback or empty return if method not applicable (e.g. no ref data)
      return(df_sub %>% mutate(z_score = NA, en_score = NA, eval_z = "N/A", eval_en = "N/A"))
  }

  df_scores <- df_sub %>%
    filter(participant_id != "ref") %>%
    left_join(targets, by = "level") %>%
    mutate(
      z_score = (mean_value - x_pt) / sigma_pt,
      # Calculate other scores if needed, but we focus on the selected metric for display
      z_prime_score = (mean_value - x_pt) / sqrt(sigma_pt^2 + u_xpt^2),
      zeta_score = (mean_value - x_pt) / sqrt(sd_value^2 + u_xpt^2),
      
      U_lab = 2 * sd_value,
      U_ref = 2 * u_xpt,
      en_score = (mean_value - x_pt) / sqrt(U_lab^2 + U_ref^2),
      
      eval_z = case_when(
        abs(z_score) <= 2 ~ "Satisfactorio",
        abs(z_score) < 3 ~ "Cuestionable",
        TRUE ~ "Insatisfactorio"
      ),
      eval_en = ifelse(abs(en_score) <= 1, "Satisfactorio", "Insatisfactorio")
    )
  
  return(df_scores)
}
```

# 1. Identificación y Contexto

## 1.1. Alcance y Objetivo del EA
Este Ensayo de Aptitud (EA) por comparación interlaboratorio abarca la medición de los gases contaminantes criterio SO₂, CO, O₃, NO y NO₂ en aire cero.

## 1.2. Confidencialidad
La identidad de los participantes es confidencial.

## 1.3. Participantes
En esta ronda participaron `r if(!is.null(params$summary_data)) length(unique(params$summary_data$participant_id)) else 0` laboratorios.

# 2. Descripción del Ensayo y Metodología

## 2.1. Ítems de Ensayo
Atmósferas de gas generadas dinámicamente.

## 2.2. Homogeneidad y Estabilidad
Se aplicó el criterio ISO 13528:2022.

```{r homogeneity_summary}
if (!is.null(params$hom_data) && !is.null(params$summary_data)) {
  pollutants <- unique(params$summary_data$pollutant)
  levels <- unique(params$summary_data$level)
  
  hom_results_df <- expand.grid(Pollutant = pollutants, Level = levels) %>%
    rowwise() %>%
    mutate(
      hom_res = list(compute_homogeneity_metrics(params$hom_data, Pollutant, Level)),
      stab_res = if(!is.null(hom_res)) list(compute_stability_metrics(params$stab_data, Pollutant, Level, hom_res)) else list(NULL),
      
      Hom_Passed = if(!is.null(hom_res)) hom_res$passed else NA,
      Stab_Passed = if(!is.null(stab_res)) stab_res$passed else NA
    ) %>%
    select(Pollutant, Level, Hom_Passed, Stab_Passed)
    
  kable(hom_results_df, caption = "Resumen de Homogeneidad y Estabilidad")
} else {
  cat("No hay datos de homogeneidad disponibles.")
}
```

## 2.3. Determinación del Valor Asignado ($X_{pt}$)
Se utilizó el Algoritmo A (ISO 13528:2022, Anexo C.3) calculado a partir de los resultados de los participantes (o valor de referencia si está disponible).

# 3. Metodología de Evaluación de Desempeño

**Criterios de Evaluación:**

*   **Z-score ($z$):**
    *   $|z| \le 2.0$: Satisfactorio
    *   $2.0 < |z| < 3.0$: Cuestionable
    *   $|z| \ge 3.0$: Insatisfactorio

*   **$E_n$-score:**
    *   $|E_n| \le 1.0$: Satisfactorio
    *   $|E_n| > 1.0$: Insatisfactorio

# 4. Resultados y Discusión

## 4.1. Resumen General

```{r scores_calc}
if (!is.null(params$summary_data)) {
  all_scores <- map_df(unique(params$summary_data$pollutant), ~calculate_scores(params$summary_data, .x, params$method))
  
  # Select the metric to display
  metric_col <- switch(params$metric,
                       "z" = "z_score",
                       "z'" = "z_prime_score",
                       "zeta" = "zeta_score",
                       "En" = "en_score")
                       
  # For summary, we might still want Z and En, or just the selected one. 
  # The user asked to make info conditional. Let's focus on the selected metric.
  
  summary_table <- all_scores %>%
    group_by(pollutant) %>%
    summarise(
      Total_Resultados = n(),
      Satisfactorio = sum(case_when(
        params$metric == "En" ~ abs(en_score) <= 1,
        TRUE ~ abs(get(metric_col)) <= 2
      ), na.rm = TRUE),
      Cuestionable = sum(case_when(
        params$metric == "En" ~ FALSE, # En doesn't have questionable
        TRUE ~ abs(get(metric_col)) > 2 & abs(get(metric_col)) < 3
      ), na.rm = TRUE),
      Insatisfactorio = sum(case_when(
        params$metric == "En" ~ abs(en_score) > 1,
        TRUE ~ abs(get(metric_col)) >= 3
      ), na.rm = TRUE)
    )
  
  kable(summary_table, caption = paste("Resumen de Desempeño (Métrica:", params$metric, ")"))
}
```

## 4.2. Evaluación por Contaminante

```{r heatmaps, results='asis'}
if (!is.null(params$summary_data) && exists("all_scores")) {
  pollutants <- unique(params$summary_data$pollutant)
  
  for(p in pollutants) {
    cat(paste("\n### 4.2.", which(pollutants == p), "Resultados para", toupper(p), "\n"))
    
    df_p <- all_scores %>% filter(pollutant == p)
    
    # Heatmap for selected metric
    cat(paste("\n#### Mapa de Calor:", params$metric, "\n"))
    
    # Determine evaluation column and colors
    if (params$metric == "En") {
      df_p$eval_plot <- df_p$eval_en
      colors <- c("Satisfactorio" = "#00B050", "Insatisfactorio" = "#D32F2F")
    } else {
      # For z, z', zeta, we use the z-score evaluation logic (Sat <=2, Ques <3, Unsat >=3)
      # We need to recalculate eval based on the specific metric if it's not z
      val <- df_p[[switch(params$metric, "z"="z_score", "z'"="z_prime_score", "zeta"="zeta_score")]]
      df_p$eval_plot <- case_when(
        abs(val) <= 2 ~ "Satisfactorio",
        abs(val) < 3 ~ "Cuestionable",
        TRUE ~ "Insatisfactorio"
      )
      colors <- c("Satisfactorio" = "#00B050", "Cuestionable" = "#FFEB3B", "Insatisfactorio" = "#D32F2F")
    }
    
    val_col <- switch(params$metric, "z"="z_score", "z'"="z_prime_score", "zeta"="zeta_score", "En"="en_score")

    p_map <- ggplot(df_p, aes(x = level, y = participant_id, fill = eval_plot)) +
      geom_tile(color = "white") +
      geom_text(aes(label = round(get(val_col), 2)), size = 3) +
      scale_fill_manual(values = colors) +
      labs(title = paste(params$metric, "Score:", toupper(p)), x = "Nivel", y = "Participante", fill = "Evaluación") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
    
    print(p_map)
    cat("\n")
  }
}
```

# 5. Conclusiones
El desempeño general de los laboratorios se presenta en las secciones anteriores.

# Anexos

## Anexo A: Valores Asignados

```{r assigned_values}
if (exists("all_scores")) {
  assigned_values <- all_scores %>%
    group_by(pollutant, level) %>%
    summarise(
      X_pt = mean(x_pt, na.rm=TRUE),
      u_Xpt = mean(u_xpt, na.rm=TRUE),
      sigma_pt = mean(sigma_pt, na.rm=TRUE),
      .groups = "drop"
    )
  
  kable(assigned_values, caption = "Valores Asignados e Incertidumbres")
}
```

## Anexo C: Resultados por Participante

```{r participant_plots, results='asis'}
if (exists("all_scores")) {
  participants <- unique(all_scores$participant_id)
  
  for(part in participants) {
    cat(paste("\n### Participante:", part, "\n"))
    
    df_part <- all_scores %>% filter(participant_id == part)
    
    p1 <- ggplot(df_part, aes(x = level, y = mean_value, group = pollutant, color = pollutant)) +
      geom_line() + geom_point() +
      labs(title = "Valores Reportados", y = "Valor") + theme_minimal() +
      theme(axis.text.x = element_text(angle = 90))
    
    p2 <- ggplot(df_part, aes(x = level, y = get(val_col), group = pollutant, color = pollutant)) +
      geom_line() + geom_point() +
      geom_hline(yintercept = if(params$metric == "En") c(1, -1) else c(2, -2), linetype = "dashed", color = "orange") +
      labs(title = paste(params$metric, "Scores"), y = params$metric) + theme_minimal() +
      theme(axis.text.x = element_text(angle = 90))
    
    print(p1 / p2)
    cat("\n")
  }
}
```
